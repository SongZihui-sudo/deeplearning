#set page(
  paper: "a4",
  margin: (x: 1.8cm, y: 1.5cm)
)

#set heading(numbering: "1.")
#set math.equation(numbering: equation => locate(loc => {
	let chapter = counter(heading).at(loc).at(0)
	[(#numbering("1", chapter)  - #numbering("1", equation))]
}))
#show heading.where(level: 1): it => [
	#counter(math.equation).update(0) #it
]
#set figure(numbering: equation => locate(loc => {
	let chapter = counter(heading).at(loc).at(0)
	[#numbering("1", chapter)  - #numbering("1", equation)]
}))

#set align(center)
#set text(24pt)

çº¿æ€§ç¥žç»ç½‘ç»œ

#set text(11pt)
#set align(left)
= çº¿æ€§å›žå½’

#link("https://promhub.top/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html")


= é€»è¾‘å›žå½’
#set par(first-line-indent: 2em)
#let indent = h(2em)

#indent åœ¨é€»è¾‘å›žå½’ä¸­å¯ä»¥é€šè¿‡ä¸€æ¡ç›´çº¿æ¥åˆ’åˆ†ä¸¤ç§ä¸åŒçš„ç±»åž‹ï¼Œä»¥æ­¤å¯ä»¥è§£å†³äºŒåˆ†ç±»é—®é¢˜ã€‚
åœ¨é€»è¾‘å›žå½’ä¸­é€šè¿‡è¡¨ç¤ºä¸ºï¼š $ hat(y) := cases(
  1 "if" f(x) > 0.5,
  0 "if" f(x) <= 0.5
) $ ä»¥è¾“å‡ºå€¼ä¸º0.5ä½œä¸ºç•Œé™è¿›è¡ŒåŒºåˆ†ã€‚

æ‹Ÿåˆçš„æ–¹ç¨‹$f(x)$ å†™ä¸ºï¼š$ f(x) = w dot x $ ä¸Žçº¿æ€§å›žå½’ç›¸ä¼¼ï¼Œåœ¨å•ç‰¹å¾æ—¶æœ‰ä¸€ä¸ªç‰¹å¾wï¼Œä¸€ä¸ªè¾“å…¥wï¼Œä¸€ä¸ªè¾“å‡ºyï¼Œåç½®bã€‚

è¿™æ ·è¿›è€Œå°±å¯ä»¥ç”± $f(x)$ å†™å‡ºä¸€ä¸ªxå…³äºŽ$hat(y)$çš„è¡¨è¾¾å¼ã€‚
$ hat(y) = cases(
  1 "if" x > f^(-1)(0.5) ,
  0 "if" x <= f^(-1)(0.5)
) $è¿™æ ·å°±å¯ä»¥é€šè¿‡è¾“å…¥xå¾—å‡ºè¾“å‡ºyã€‚

è¿™ä¸ªå‡½æ•°æ˜¯é—´æ–­çš„ï¼Œä¸é€‚ç”¨äºŽä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•è¿›è¡Œå¤„ç†ï¼Œè¿™æ ·å°±å¯ä»¥ä½¿ç”¨æ›´åŠ å¹³æ»‘çš„ sigmond å‡½æ•°æ¥ä»£æ›¿ã€‚sigmondå‡½æ•°å¯ä»¥å†™ä¸º$ "f(z)" = frac(1, 1 + e^(-z)) \
                   z = w dot x $
== æžå¤§ä¼¼ç„¶ä¼°è®¡

#indent æ¦‚çŽ‡æè¿°çš„æ˜¯ä¸€ä¸ªäº‹ä»¶å‘ç”Ÿçš„å¯èƒ½æ€§ï¼Œä¼¼ç„¶æ€§æ˜¯æ”¾è¿‡æ¥åœ¨äº‹ä»¶å‘ç”ŸåŽåæŽ¨åœ¨ä»€ä¹ˆå‚æ•°æ¡ä»¶ä¸‹ï¼Œè¿™ä¸ªäº‹ä»¶å‘ç”Ÿçš„æ¦‚çŽ‡æœ€å¤§ï¼ˆä¾‹å¦‚ä¸‹é›¨ï¼ˆæžœï¼‰çš„æ—¶å€™æœ‰ä¹Œäº‘ï¼ˆå› /è¯æ®/è§‚å¯Ÿçš„æ•°æ®ï¼‰çš„æ¦‚çŽ‡ï¼Œå³å·²ç»æœ‰äº†æžœï¼Œå¯¹è¯æ®å‘ç”Ÿçš„å¯èƒ½æ€§æè¿°ï¼‰ã€‚æ•°å­¦è¯­è¨€å¯ä»¥å°†å…¶å†™ä¸ºï¼š
$ P(x|beta) = a \
 L(beta|x) = a \
 P(x|beta) = L(beta|x) $ äºŒè€…æ˜¯ç›¸ç­‰çš„ã€‚

åœ¨äºŒåˆ†ç±»é—®é¢˜ä¸­å¯ä»¥æ¦‚çŽ‡å†™ä¸ºï¼š
$ P(y|x, beta)=P(y=1)^(y)P(Y=0)^(1-y) \
  P(y|x, beta) = frac(1, 1 + e^(-z))^y (1-frac(1, 1 + e^(-z)))^(1-y) $ã€‚

#show math.equation: set text(13pt)
å¾—åˆ°æœ€å¤§å€¼ï¼š$ L(beta) = attach(
  Pi,
  t: n,
  b: i=1
)P(y_i|x_i,beta) = attach(
  Pi,
  t: n,
  b: i=1
)  frac(1, 1 + e^(-w dot x_i))^(y_i) (1-frac(1, 1 + e^(-w dot x_i)))^(1-y_i)  $

#show math.equation: set text(11pt)
å¯¹å…¶å–å¯¹æ•°å¯å¾—ï¼š
$ log(L(beta)) = sum^(n)_(i=1)(y_i dot log(frac(1, 1 + e^(-w dot x_i))^(y_i)) + log((1-y_i) dot (1-frac(1, 1 + e^(-w dot x_i)))^(1-y_i))) $

== æŸå¤±å‡½æ•°

#indent æŸå¤±å‡½æ•°æ˜¯ç”¨äºŽè¡¡é‡é¢„æµ‹å€¼ä¸Žå®žé™…å€¼çš„åç¦»ç¨‹åº¦ï¼Œå³æ¨¡åž‹é¢„æµ‹çš„é”™è¯¯ç¨‹åº¦ã€‚é€šè¿‡å¯»æ‰¾è¯¯å·®æœ€å°æ—¶çš„å‚æ•°æ¥ç¡®å®šå‡ºæœ€ä½³çš„æ¨¡åž‹ã€‚

ä½¿ç”¨å¹³æ–¹æŸå¤±ï¼š
$ Q = sum^n_(i = 1)(y_i - hat(y_i))^2 $

å¾…å…¥åˆ°é€»è¾‘å›žå½’ä¸­æŸå¤±å‡½æ•°å°±æ˜¯ï¼š
$ Q = sum^n_(i = 1)(y_i - 1 / (1 + e^(-w * x))) $å› ä¸ºè¿™ä¸ªå‡½æ•°ä¸æ­»å‡¸å‡½æ•°ï¼Œæ‰€ä»¥ä½¿ç”¨å¯¹æ•°æŸå¤±å‡½æ•°ã€‚
$ Q = -log(L(beta))  $

= å¤šå…ƒçº¿æ€§å›žå½’

#indent å¤šå…ƒçº¿æ€§å›žå½’ç›¸æ¯”äºŽçº¿æ€§å›žå½’ï¼Œç‰¹å¾ä¸Žè¾“å…¥å¤šä½™çº¿æ€§å›žå½’ã€‚å½¢å¼ä¸ºï¼š$ hat(y) = w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4 + ......... + b $ å¯ä»¥å°†å…¶å†™æˆçŸ©é˜µçš„å½¢å¼ï¼š$ mat(x_1, x_2, x_3) dot mat(w_1;w_2;w_3) + mat(b) = w_1x_1 + w_2x_2 + w_3x_3 + b$
ç›¸å½“äºŽæ˜¯ä¸€ä¸ªç‚¹ä¹˜ã€‚

è¿›è€Œå¯ä»¥ç”¨çŸ©é˜µ$X = mat(x_11, x_12, x_13;x_21, x_22, x_23;x_31, x_32, x_33)$ æ¥è¡¨ç¤ºæ•°æ®é›†ï¼Œä¸€è¡Œè¡¨ç¤ºä¸€ç»„æ•°æ®ï¼Œä¸€åˆ—å¯¹åº”ä¸ŽæŸç‰¹å¾å€¼ã€‚ä½¿ç”¨çŸ©é˜µ$W = mat(w_1, w_2, w_3)$ æ¥è¡¨ç¤ºç‰¹å¾, åç½®å¯ä»¥è¡¨ç¤ºä¸ºï¼š$mat(b)$ã€‚è¿™æ ·è®¡ç®—çŸ©é˜µï¼š$ hat(y) = X times W^T + b= mat(mat(x_11, x_12, x_13) dot mat(w_1;w_2;w_3) + b;
mat(x_21, x_22, x_23) dot mat(w_1;w_2;w_3) + b;
mat(x_31, x_32, x_33) dot mat(w_1;w_2;w_3) + b) $

ä½¿ç”¨å¹³æ–¹æŸå¤±å‡½æ•°ï¼š
$ Q = sum^n_(i = 1)(y_i - hat(y_i))^2 $

= Softmax å›žå½’

#indent åœ¨å‰é¢çš„é€»è¾‘å›žå½’ï¼Œå®ƒä¸»è¦åº”ç”¨ä¸ŽäºŒåˆ†ç±»é—®é¢˜ï¼Œå¯¹äºŽå¤šåˆ†ç±»é—®é¢˜ï¼Œæœ‰å¤šä¸ªè¾“å…¥ï¼Œå¤šä¸ªç‰¹å¾ï¼Œå¤šä¸ªè¾“å‡ºã€‚

#figure(
  image("./static/softmaxreg.svg", width: 70%),
  caption: [
    ç½‘ç»œå›¾
  ],
)
å¯ä»¥è¡¨ç¤ºä¸ºï¼š$ o_1 = x_1w_11 + x_2w_12 + x_2w_13+ b_1 \
o_2 = x_1w_21 + x_2w_22 + x_2w_23+ b_2 \
o_3 = x_1w_31 + x_2w_32 + x_2w_33+ b_3 $ ä½¿ç”¨ä¸‰ä¸ªçº¿æ€§çš„è¡¨è¾¾å¼è¡¨ç¤ºã€‚

å°†å…¶å†™æˆçŸ©é˜µå½¢å¼ï¼Œå¯ä»¥è¡¨ç¤ºä¸ºï¼š
$ mat(w_11, w_12, w_13;
w_21, w_22, w_23;
w_31, w_32, w_33;) times mat(x_1;x_2; x_3) + mat(b_1;b_2;b_3) \
mat(mat(x_1, x_2, x_3) dot mat(w_11;w_12;w_13) + b_1;
 mat(x_1, x_2, x_3) dot mat(w_21;w_22;w_23) + b_1;
 mat(x_1, x_2, x_3) dot mat(w_31;w_32;w_33) + b_3;
 ) $åœ¨è¿™ä¸ªä¾‹å­ä¸­è¾“å…¥çš„ä¸ªæ•°ä¸º3ï¼Œè¾“å‡ºçš„ä¸ªæ•°ä¸º3ï¼Œç‰¹å¾çš„ä¸ªæ•°ä¸º3ï¼Œå¯ä»¥ç®€å†™ä¸º$O = X W^T + b$ã€‚

å› ä¸ºç”±ä¸Šè¿°çš„çº¿æ€§è¡¨è¾¾å¼å¾—å‡ºçš„ç»“æžœå¯èƒ½ä¸ºæ­£å¯èƒ½ä¸ºè´Ÿï¼Œä¸‰ä¸ªè¾“å‡ºä¹‹å’Œä¹Ÿå¯èƒ½å¤§äºŽ1ï¼Œè¿™æ ·éƒ½ä¼šè¿èƒŒæ¦‚çŽ‡çš„å®šç†ï¼Œæ‰€ä»¥ä½¿ç”¨softmaxå‡½æ•°æ¥è§„èŒƒå¾—åˆ°çš„ç»“æžœã€‚Softmaxå‡½æ•°å¯ä»¥å†™ä¸ºï¼š$ hat(y) = "softmax"(o) \
  hat(y_i) = exp(o_j) / (sum_(k)exp(o_k)) $
è¿™æ ·å°±å¯ä»¥çš„å¾—åˆ°$hat(y_1) = exp(o_1) / (sum_(k)exp(o_k))$ï¼Œ$hat(y_2) = exp(o_2) / (sum_(k)exp(o_k))$ï¼Œ$hat(y_3) = exp(o_3) / (sum_(k)exp(o_k))$ã€‚å¯ä»¥å–$attach("argmax", b: i)(o_i) = attach("argmax", b:i)(hat(y_i))$ä½œä¸ºè¾“å‡ºå€¼ã€‚

å¯ä»¥å¾—å‡ºsoftmaxå›žå½’çš„è®¡ç®—è¡¨è¾¾å¼ä¸ºï¼š$ o^i = x^i w + b \ 
  hat(y^i) = "softmax"(o_i) $

== äº¤å‰ç†µ

#indent äº¤å‰ç†µå¯ä»¥è¡¨ç¤ºä¸ºï¼š$ H(y^(i), hat(y)^(i)) = -sum^n_(i = 1)P(x_(i))log(P(x_i)) $$ð‘(ð‘¥_i)$ä»£è¡¨éšæœºäº‹ä»¶ð‘¥ð‘–çš„æ¦‚çŽ‡ã€‚

ä¿¡æ¯é‡æ˜¯å¯¹ä¿¡æ¯çš„åº¦é‡ã€‚æŽ¥å—åˆ°çš„ä¿¡æ¯é‡è·Ÿå…·ä½“å‘ç”Ÿçš„äº‹ä»¶æœ‰å…³ã€‚è¶Šå°æ¦‚çŽ‡çš„äº‹æƒ…å‘ç”Ÿäº†äº§ç”Ÿçš„ä¿¡æ¯é‡è¶Šå¤§ï¼Œè¶Šå¤§æ¦‚çŽ‡çš„äº‹æƒ…å‘ç”Ÿäº†äº§ç”Ÿçš„ä¿¡æ¯é‡è¶Šå°ã€‚æœ‰2ä¸ªä¸ç›¸å…³çš„äº‹ä»¶xå’Œyï¼Œé‚£ä¹ˆæˆ‘ä»¬è§‚å¯Ÿåˆ°çš„ä¿©ä¸ªäº‹ä»¶åŒæ—¶å‘ç”Ÿæ—¶èŽ·å¾—çš„ä¿¡æ¯åº”è¯¥ç­‰äºŽè§‚å¯Ÿåˆ°çš„äº‹ä»¶å„è‡ªå‘ç”Ÿæ—¶èŽ·å¾—çš„ä¿¡æ¯ä¹‹å’Œ$h(x, y) = h(x) + h(y)$,ç”±äºŽxï¼Œyæ˜¯ä¿©ä¸ªä¸ç›¸å…³çš„äº‹ä»¶ï¼Œé‚£ä¹ˆæ»¡è¶³ $p(x,y) = p(x) times p(y)$è¿™æ ·å°±å¾—å‡ºä¿¡æ¯é‡çš„å…¬å¼ï¼š$ h(x) = -log_2(p(x)) $
ä¿¡æ¯ç†µæ˜¯åœ¨ç»“æžœå‡ºæ¥ä¹‹å‰å¯¹å¯èƒ½äº§ç”Ÿçš„ä¿¡æ¯é‡çš„æœŸæœ›â€”â€”è€ƒè™‘è¯¥éšæœºå˜é‡çš„æ‰€æœ‰å¯èƒ½å–å€¼ï¼Œå³æ‰€æœ‰å¯èƒ½å‘ç”Ÿäº‹ä»¶æ‰€å¸¦æ¥çš„ä¿¡æ¯é‡çš„æœŸæœ›ã€‚å°±å¯ä»¥ç”¨å‰é¢çš„å…¬å¼4-5è¡¨ç¤ºã€‚

== äº¤å‰ç†µæŸå¤±å‡½æ•°

#indent äº¤å‰ç†µæŸå¤±å‡½æ•°å¯ä»¥å®šä¹‰ä¸ºï¼š$ l(theta) = 1/n sum^n_(i = 1)H(y^i, hat(y)^i) $

= å¼•ç”¨

1. ã€Š3.4. softmaxå›žå½’ â€” åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹  2.0.0 documentationã€‹. è§äºŽ 2024å¹´5æœˆ4æ—¥. https://zh.d2l.ai/chapter_linear-networks/softmax-regression.html.

2. ã€Š3.4. softmaxå›žå½’ â€” ã€ˆåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ã€‰ æ–‡æ¡£ã€‹. è§äºŽ 2024å¹´5æœˆ4æ—¥. https://zh-v1.d2l.ai/chapter_deep-learning-basics/softmax-regression.html.

3. ã€Šå¤šå…ƒçº¿æ€§å›žå½’æ¨¡åž‹ï¼ˆå…¬å¼æŽ¨å¯¼+ä¸¾ä¾‹åº”ç”¨ï¼‰-CSDNåšå®¢ã€‹. è§äºŽ 2024å¹´5æœˆ4æ—¥. https://blog.csdn.net/qq_46117575/article/details/135450470.
4. ã€Šä¸€æ–‡è¯¦è§£Softmaxå‡½æ•° - çŸ¥ä¹Žã€‹. è§äºŽ 2024å¹´5æœˆ4æ—¥. https://zhuanlan.zhihu.com/p/105722023.

5. ã€Šç”¨äººè¯è®²æ˜Žç™½é€»è¾‘å›žå½’Logistic regression - çŸ¥ä¹Žã€‹. è§äºŽ 2024å¹´5æœˆ4æ—¥. https://zhuanlan.zhihu.com/p/139122386.

6. çŸ¥ä¹Žä¸“æ . ã€Šé€šä¿—ç†è§£ä¿¡æ¯ç†µã€‹. è§äºŽ 2024å¹´5æœˆ4æ—¥. https://zhuanlan.zhihu.com/p/26486223.